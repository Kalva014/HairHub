{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1h3Z-3Z5gfdZsFxaRaRfYJGYMFtpa18PC",
      "authorship_tag": "ABX9TyMr4FDOM5GFNvlOEjsaYtbb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kalva014/HairHub/blob/main/colab_notebooks/Upload_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SZ7vpIQ6_zg7",
        "outputId": "112eb81d-445b-4219-d9d1-56c87cb143d0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.35.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.11.17)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import libraries\n",
        "import torch\n",
        "import os\n",
        "import json"
      ],
      "metadata": {
        "id": "y50N4vfV_7v2"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Instantiate and initialize unet model\n",
        "class UNet(torch.nn.Module):\n",
        "    def __init__(self, input_channels, num_classes):\n",
        "        super(UNet, self).__init__()\n",
        "        self.input_channels = input_channels\n",
        "        self.num_classes = num_classes\n",
        "\n",
        "        # Encoder\n",
        "        self.conv1 = torch.nn.Conv2d(self.input_channels, 64, kernel_size=3, padding=1)\n",
        "        self.conv2 = torch.nn.Conv2d(64, 64, kernel_size=3, padding=1)\n",
        "        self.pool1 = torch.nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        self.conv3 = torch.nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
        "        self.conv4 = torch.nn.Conv2d(128, 128, kernel_size=3, padding=1)\n",
        "        self.pool2 = torch.nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        self.conv5 = torch.nn.Conv2d(128, 256, kernel_size=3, padding=1)\n",
        "        self.conv6 = torch.nn.Conv2d(256, 256, kernel_size=3, padding=1)\n",
        "        self.pool3 = torch.nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        self.conv7 = torch.nn.Conv2d(256, 512, kernel_size=3, padding=1)\n",
        "        self.conv8 = torch.nn.Conv2d(512, 512, kernel_size=3, padding=1)\n",
        "        self.pool4 = torch.nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        # Middle\n",
        "        self.conv9 = torch.nn.Conv2d(512, 1024, kernel_size=3, padding=1)\n",
        "        self.conv10 = torch.nn.Conv2d(1024, 1024, kernel_size=3, padding=1)\n",
        "\n",
        "        # Decoder\n",
        "        self.up1 = torch.nn.ConvTranspose2d(1024, 512, kernel_size=2, stride=2)\n",
        "        self.conv11 = torch.nn.Conv2d(1024, 512, kernel_size=3, padding=1)\n",
        "\n",
        "        self.up2 = torch.nn.ConvTranspose2d(512, 256, kernel_size=2, stride=2)\n",
        "        self.conv13 = torch.nn.Conv2d(512, 256, kernel_size=3, padding=1)\n",
        "\n",
        "        self.up3 = torch.nn.ConvTranspose2d(256, 128, kernel_size=2, stride=2)\n",
        "        self.conv15 = torch.nn.Conv2d(256, 128, kernel_size=3, padding=1)\n",
        "\n",
        "        # Output\n",
        "        self.out = torch.nn.Conv2d(128, self.num_classes, kernel_size=1)\n",
        "        self.upsample = torch.nn.Upsample((256, 256), mode='bilinear', align_corners=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Encoder\n",
        "        x1 = torch.nn.functional.relu(self.conv1(x))\n",
        "        x2 = torch.nn.functional.relu(self.conv2(x1))\n",
        "        p1 = self.pool1(x2)\n",
        "\n",
        "        x3 = torch.nn.functional.relu(self.conv3(p1))\n",
        "        x4 = torch.nn.functional.relu(self.conv4(x3))\n",
        "        p2 = self.pool2(x4)\n",
        "\n",
        "        x5 = torch.nn.functional.relu(self.conv5(p2))\n",
        "        x6 = torch.nn.functional.relu(self.conv6(x5))\n",
        "        p3 = self.pool3(x6)\n",
        "\n",
        "        x7 = torch.nn.functional.relu(self.conv7(p3))\n",
        "        x8 = torch.nn.functional.relu(self.conv8(x7))\n",
        "        p4 = self.pool4(x8)\n",
        "\n",
        "        # Middle\n",
        "        x9 = torch.nn.functional.relu(self.conv9(p4))\n",
        "        x10 = torch.nn.functional.relu(self.conv10(x9))\n",
        "\n",
        "        # Decoder\n",
        "        x = self.up1(x10)\n",
        "        x = torch.cat([x, x8], dim=1)\n",
        "        x = torch.nn.functional.relu(self.conv11(x))\n",
        "\n",
        "        x = self.up2(x)\n",
        "        x = torch.cat([x, x6], dim=1)\n",
        "        x = torch.nn.functional.relu(self.conv13(x))\n",
        "\n",
        "        x = self.up3(x)\n",
        "        x = torch.cat([x, x4], dim=1)\n",
        "        x = torch.nn.functional.relu(self.conv15(x))\n",
        "\n",
        "        # Output\n",
        "        x = self.out(x)\n",
        "        x = self.upsample(x)  # Upsample to match the original size\n",
        "\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "t4dkwqAnAE6H"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load pth file which has both the aka weights and biases into the model\n",
        "model = UNet(input_channels=3, num_classes=1)\n",
        "checkpoint = torch.load('/content/drive/MyDrive/Hairhub_data/unet_model.pth') # Have to load the file as a checkpoint because it also has the optimizer values\n",
        "model.load_state_dict(checkpoint['model_state_dict'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E8uAHJLyAMX_",
        "outputId": "60f9dc23-6a13-4e7b-e92d-f65965056afe"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a config file (modify as needed)\n",
        "config = {\n",
        "    \"input_channels\": 3,\n",
        "    \"num_classes\": 1,\n",
        "}\n",
        "\n",
        "with open('/content/drive/MyDrive/Hairhub_data/trained_model/config.json', 'w') as f:\n",
        "    json.dump(config, f)"
      ],
      "metadata": {
        "id": "g2wzbKXPF_mt"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Write a README file\n",
        "with open('/content/drive/MyDrive/Hairhub_data/trained_model/README.md', 'w') as f:\n",
        "    f.write(\"# Hair Segmentation\\n\\nDescription...FIX LATER\")"
      ],
      "metadata": {
        "id": "NmdNbb_IGPtp"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# n the parent directory (not inside your_model_directory)\n",
        "!zip -r /content/drive/MyDrive/Hairhub_data/HairSegmentation.zip /content/drive/MyDrive/Hairhub_data/trained_model/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4EckpRIyGh2b",
        "outputId": "c72d2e06-06d5-4228-bd95-2a7f4cc368bd"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: content/drive/MyDrive/Hairhub_data/trained_model/ (stored 0%)\n",
            "  adding: content/drive/MyDrive/Hairhub_data/trained_model/unet_model.pth (deflated 6%)\n",
            "  adding: content/drive/MyDrive/Hairhub_data/trained_model/config.json (stored 0%)\n",
            "  adding: content/drive/MyDrive/Hairhub_data/trained_model/README.md (deflated 2%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!huggingface-cli login --token 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\n",
        "!huggingface-cli upload \"Kalva014/hair-segmentation\" \"/content/drive/MyDrive/Hairhub_data/HairSegmentation.zip\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T8MQN_AHBEiB",
        "outputId": "3b019356-9ac3-4378-f94e-e908dbe21198"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Token will not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\n",
            "Token is valid (permission: write).\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful\n",
            "Consider using `hf_transfer` for faster uploads. This solution comes with some limitations. See https://huggingface.co/docs/huggingface_hub/hf_transfer for more details.\n",
            "HairSegmentation.zip: 100% 315M/315M [00:12<00:00, 25.7MB/s]\n",
            "https://huggingface.co/Kalva014/hair-segmentation/blob/main/HairSegmentation.zip\n"
          ]
        }
      ]
    }
  ]
}