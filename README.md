# HairHub
<!-- TABLE OF CONTENTS -->
<details>
  <summary>Table of Contents</summary>
  <ol>
    <li>
      <a href="#about-the-project">About The Project</a>
      <ul>
        <li><a href="#built-with">Built With</a></li>
        <li><a href="#datasets--models">Datasets & Models</a></li>
        <li><a href="#examples">Examples</a></li>
      </ul>
    </li>
    <li>
      <a href="#getting-started">Getting Started</a>
      <ul>
        <li><a href="#prerequisites">Prerequisites</a></li>
        <li><a href="#installation">Installation</a></li>
      </ul>
    </li>
    <li><a href="#license">License</a></li>
    <li><a href="#contact">Contact</a></li>
    <li><a href="#acknowledgments">Acknowledgments</a></li>
  </ol>
</details>

<!-- ABOUT THE PROJECT -->
## About The Project

Finish later

<p align="right">[<a href="#readme-top">Back to Top</a>]</p>

### Built With

* <a href="https://pytorch.org/"><img src="images/pytorch.png" width="70" height="30"></a>
* <a href="https://colab.research.google.com/"><img src="images/colab.png" width="70" height="30"></a>
* <a href="https://huggingface.co/"><img src="images/huggingface.png" width="80" height="30"></a>

<p align="right">[<a href="#readme-top">Back to Top</a>]</p>

### Datasets & Models

The datasets that we experimented with for the fine-tuning process are listed below. They are all on HuggingFace.

1.

The models that were obtained as a result of fine-tuning with these datasets are listed below. These are all on HuggingFace.

1. 

<p align="right">[<a href="#readme-top">Back to Top</a>]</p>

### Examples

1. First text prompt: "Snowy cabin in the woods"

   Second text prompt: "A medieval castle"

   See [here](./colab-notebooks/MorphImages1.ipynb) for more details.


<p align="right">[<a href="#readme-top">Back to Top</a>]</p>

<!-- GETTING STARTED -->
## Getting Started

To get a local copy up and running follow these simple example steps.

### Prerequisites

A powerful GPU is necessary for most parts, so one may opt to use Google Colaboratory where an A100 high-RAM GPU is easily available with the Colab Pro plan.

### Installation

1. Clone the repo
   ```sh
   FIX THIS LATER
   ```
2. Install the requirements (install diffusers and transformers libraries at a minimum for inference)
  ```
  FIX THIS LATER
  pip install -r requirements.txt
  ```
  
Model Fine-Tuning

1. 

<!-- LICENSE -->
## License

Distributed under the MIT License. See `LICENSE.txt` for more information.

<p align="right">[<a href="#readme-top">Back to Top</a>]</p>

<!-- CONTACT -->
## Contact

[Kenneth Alvarez](https://github.com/Kalva014)

Project Link: FIX THIS LATER

<p align="right">[<a href="#readme-top">Back to Top</a>]</p>

<!-- ACKNOWLEDGMENTS -->
## Acknowledgments

FILL THIS OUT LATER

<p align="right">[<a href="#readme-top">Back to Top</a>]</p>
